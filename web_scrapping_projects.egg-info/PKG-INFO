Metadata-Version: 2.1
Name: web_scrapping_projects
Version: 0.0.1
Summary: A Python package for web scraping
Home-page: https://github.com/HarshalHonde50/WebScrapping
Author: Harshal Honde
Author-email: Harshalhonde50@gmail.com
Project-URL: Bug Tracker, https://github.com/HarshalHonde50/WebScrapping/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: Windows
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE

# web_scraping_project/

â”‚
â”œâ”€â”€ src/                   # Source code folder
â”‚   â”œâ”€â”€ __init__.py        # Package initialization file
â”‚   â”œâ”€â”€ scrapers/          # Folder for scraper modules
â”‚   â”‚   â”œâ”€â”€ __init__.py    # Package initialization file
â”‚   â”‚   â””â”€â”€ scraper1.py    # Scraper module 1
â”‚   â”‚   â””â”€â”€ scraper2.py    # Scraper module 2
â”‚   â”‚   â””â”€â”€ ...            # Other scraper modules
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/             # Folder for utility functions
â”‚   â”‚   â”œâ”€â”€ __init__.py    # Package initialization file
â”‚   â”‚   â””â”€â”€ helpers.py     # Helper functions
â”‚   â”‚
â”‚   â””â”€â”€ main.py            # Main script to run the scraping process
â”‚
â”œâ”€â”€ data/                  # Folder to store scraped data
â”‚   â””â”€â”€ output/            # Folder to store final output files
â”‚       â””â”€â”€ output.csv     # Final output CSV file
â”‚       â””â”€â”€ output.json    # Final output JSON file
â”‚       â””â”€â”€ ...            # Other output files
â”‚
â”œâ”€â”€ notebooks/             # Folder for Jupyter notebooks (optional)
â”‚
â”œâ”€â”€ requirements.txt       # File listing all Python dependencies
â””â”€â”€ README.md              # Project documentation

# ğŸ•¸ï¸ Web Scraping Repository

Welcome to the Web Scraping Repository! Explore a variety of web scraping projects covering diverse topics like crude oil, cryptocurrencies, Glassdoor job data, real estate, and SpaceX. Each project is equipped with its own set of web scraping tools, and we've provided links to the code so you can dive right in.

## Projects

### ğŸ›¢ï¸ Crude Oil

- __Directory__: [Crude_oil](./Crude_oil/Crude_oil/spiders/Oil_data.py)
- __Last Update__: [Last Commit](./Crude_Oil)
- __Description__: Web scraping project related to crude oil data.
- __Tools Used__: BeautifulSoup, Requests

### ğŸ“š Ebook

- __Directory__: [Ebook](./Ebook)
- __Last Update__: [Last Commit](./Ebook)
- __Description__: Web scraping project related to ebooks.
- __Tools Used__: Scrapy, Selenium

### ğŸ’° Crypto

- __Directory__: [Crypto](./crypto/crypto/spiders)
- __Last Update__: [Last Commit](./crypto)
- __Description__: Web scraping project related to cryptocurrency data.
- __Tools Used__: BeautifulSoup, Requests

### ğŸ¢ Glassdoor

- __Directory__: [Glassdoor](./glassdoor)
- __Last Update__: [Last Commit](./glassdoor)
- __Description__: Web scraping project related to Glassdoor job data.
- __Tools Used__: Scrapy, Selenium

### ğŸ¡ Real Estate

- __Directory__: [Real_estate](./real_estate)
- __Last Update__: [Last Commit](./real_estate)
- __Description__: Web scraping project related to real estate data.
- __Tools Used__: BeautifulSoup, Requests

### ğŸš€ SpaceX

- __Directory__: [SpaceX](./spacex)
- __Last Update__: [Last Commit](./spacex)
- __Description__: Web scraping project related to SpaceX data.
- __Tools Used__: Scrapy, Selenium

## How to Use

Each subdirectory contains its respective web scraping project. To explore the code and data, click on the directory name, and you'll find detailed instructions and scripts.

## Contribution

Feel free to contribute to any of these projects or create new ones. We welcome your ideas and enhancements to our web scraping efforts.

## License

This repository is open source and available under the [MIT License](./LICENSE).

Happy scraping! ğŸŒğŸ”
